{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Map Reduce Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map reduce is very functional algorithm where three parts of it can easily executed on different machines. In this assignment, we will try to implement this algorithm into a >100 million rows dataset.\n",
    "\n",
    "For comparison, we will have two ways of getting counts of carriers.\n",
    "\n",
    "1. Serial way - Looping through each record and counting each airline's flight\n",
    "2. Map reduce way - map, reduce and sort, and collect way to counn the flights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import utils\n",
    "import data_handler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download status:  [####################] 100% \n"
     ]
    }
   ],
   "source": [
    "data_handler.download_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all files under data folder\n",
    "file_list = sorted(glob.glob(os.path.join('data', '*.csv.bz2')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "carrier_counts = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Serial Way\n",
    "\n",
    "Here, we are getting a list of files under the data folder. The serial way requires to loop through all of the records and update one by one. \n",
    "\n",
    "If you think your computer is fast enough, you can also try `read_as_dataframe` in data_handler module. You can simply use the following code rather than looping through each file.\n",
    "\n",
    "```py\n",
    "# inital value dictionary\n",
    "carrier_counts = {}\n",
    "\n",
    "# read all datasets into one\n",
    "df = data_handler.read_as_dataframe()\n",
    "\n",
    "# unique careers\n",
    "carriers = df.UniqueCarrier.unique()\n",
    "\n",
    "# get the counts\n",
    "for carrier in df.UniqueCarrier:\n",
    "    carrier_counts[carrier] += 1\n",
    "```\n",
    "\n",
    "Since my computer wasn't able to finish it, I prefered the loop. Hopefully, you won't run into these issues thanks to the Map Reduce Algorithm!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (7009728, 29) ; 1626.26 Mb [####################] 100% \n"
     ]
    }
   ],
   "source": [
    "for ind, data_file in enumerate(file_list):\n",
    "    # read current data\n",
    "    df = pd.read_csv(data_file, encoding='ISO-8859-1', memory_map=True, low_memory=False) \n",
    "    \n",
    "    # unique airlines in dataset\n",
    "    carriers = df.UniqueCarrier.unique()\n",
    "    \n",
    "    # update the global carrier_count\n",
    "    for key in carriers:\n",
    "        if key not in carrier_counts:\n",
    "            carrier_counts.update({key: 0})\n",
    "    \n",
    "    # loop through each row in dataframe \n",
    "    for carrier in df.UniqueCarrier:\n",
    "        carrier_counts[carrier] += 1\n",
    "\n",
    "    # info \n",
    "    prefix ='Shape: {} ; {} Mb'.format(\n",
    "        df.shape, round(df.memory_usage().sum() / 1e+6,2))\n",
    "    \n",
    "    # track the progress\n",
    "    utils.progressbar(len(file_list), ind + 1, prefix=prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PS': 83617,\n",
       " 'TW': 3757747,\n",
       " 'UA': 13299817,\n",
       " 'WN': 15976022,\n",
       " 'EA': 919785,\n",
       " 'HP': 3636682,\n",
       " 'NW': 10292627,\n",
       " 'PA (1)': 316167,\n",
       " 'PI': 873957,\n",
       " 'CO': 8145788,\n",
       " 'DL': 16547870,\n",
       " 'AA': 14984647,\n",
       " 'US': 14075530,\n",
       " 'AS': 2878021,\n",
       " 'ML (1)': 70622,\n",
       " 'AQ': 154381,\n",
       " 'MQ': 3954895,\n",
       " 'OO': 3090853,\n",
       " 'XE': 2350309,\n",
       " 'TZ': 208420,\n",
       " 'EV': 1697172,\n",
       " 'FL': 1265138,\n",
       " 'B6': 811341,\n",
       " 'DH': 693047,\n",
       " 'HA': 274265,\n",
       " 'OH': 1464176,\n",
       " 'F9': 336958,\n",
       " 'YV': 854056,\n",
       " '9E': 521059}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "carrier_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map Reduce Way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "from itertools import groupby \n",
    "\n",
    "datas = pd.DataFrame()\n",
    "columns = ['Year','UniqueCarrier']\n",
    "for ind, data_file in enumerate(file_list):\n",
    "    df = pd.DataFrame(pd.read_csv(data_file, encoding='ISO-8859-1', memory_map=True, low_memory=False, usecols=columns))\n",
    "    \n",
    "    datas = datas.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "carriers = datas.UniqueCarrier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Map Reduce Algorithm phases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phase 1 :- Mapping\n",
    "\n",
    "mapping = map(lambda x: (x, 1),carriers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phase 2 :- Shuffling\n",
    "\n",
    "sorted_mapping = sorted(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('9E', 521059), ('AA', 14984647), ('AQ', 154381), ('AS', 2878021), ('B6', 811341), ('CO', 8145788), ('DH', 693047), ('DL', 16547870), ('EA', 919785), ('EV', 1697172), ('F9', 336958), ('FL', 1265138), ('HA', 274265), ('HP', 3636682), ('ML (1)', 70622), ('MQ', 3954895), ('NW', 10292627), ('OH', 1464176), ('OO', 3090853), ('PA (1)', 316167), ('PI', 873957), ('PS', 83617), ('TW', 3757747), ('TZ', 208420), ('UA', 13299817), ('US', 14075530), ('WN', 15976022), ('XE', 2350309), ('YV', 854056)]\n"
     ]
    }
   ],
   "source": [
    "# Phase 3 :- Reducing\n",
    "\n",
    "grouper = groupby(sorted_mapping, lambda p: p[0])\n",
    "final = map(lambda 1: (1[0], reduce(lambda x, y: x + y, map(lambda p: p[1], 1[1]))),grouper)\n",
    "\n",
    "print(list(final))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we are getting counts of carriers in two ways.\n",
    "\n",
    "1) Serial way - Looping through each record and counting each airline's flight\n",
    "\n",
    "2) Map reduce way - map, reduce and sort, and collect way to count the flights\n",
    "\n",
    "Map reduce way means Map Reduce algorithm contains Three important task mapping, sorting and reducing. With using these, split into small parts and asign them to multiple system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
